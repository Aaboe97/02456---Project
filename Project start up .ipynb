{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a618c9",
   "metadata": {},
   "source": [
    "# FFNN: Single layer example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def init(dims):\n",
    "    # We initalize the weights in this case I use where there are a input layer x layer z and output y,\n",
    "    # so z+y weights to initalize. The initalized are scale for input, so its variance scaled correctly.\n",
    "    \n",
    "    # INPUT: Dimesnion of the single layer network\n",
    "    # OUTPUT: Initalized weight matrix, with each column is a weight fx x->z.\n",
    "    \n",
    "    x,z,y=dims\n",
    "    w = np.sqrt(1/(x+1))\n",
    "    W = []\n",
    "    W.append(w*np.random.randn(x+1,z))\n",
    "    w = np.sqrt(1/(z+1))\n",
    "    W.append(w*np.random.randn(z+1,y))\n",
    "    return W\n",
    "\n",
    "def forward(X, W, n):\n",
    "    # INPUT: X: Training data, W: Weight matrix, n: points used for training. \n",
    "    # OUTPUT: y: Outbut of FFNN, h: a, activation for hidden layer.  \n",
    "    \n",
    "    # A fully connected neural network with a_1=max(0,z) (ReLU) as acitvation func and y_out=a_out=softmax(y)\n",
    "    \n",
    "    # Look only at subsection of data ( a bit too simple, but for example sake)\n",
    "    x = X[:,0:n]\n",
    "    x.shape\n",
    "    x = np.vstack((x, np.ones((1,n))))\n",
    "    x.shape\n",
    "\n",
    "    # % FFNN\n",
    "    # First layer\n",
    "    z = W[0].T@x\n",
    "    h = np.maximum(0, z)\n",
    "    \n",
    "    # Second layer\n",
    "    y_hat = W[1].T@np.vstack((h, np.ones((1,n))))\n",
    "    y = np.exp(y_hat)/(np.exp(y_hat).sum(axis=0))\n",
    "    \n",
    "    return y, h\n",
    "\n",
    "def backward(X, T, W, n,lr):\n",
    "    # INPUT: X: Data, T: training sta, W: weights, n: nr trainings points, lr: Learning rate\n",
    "    \n",
    "    # Perfom foreward \n",
    "    y, h = forward(X, W, n)\n",
    "    \n",
    "    \n",
    "    x = X[:,0:n]\n",
    "    x.shape\n",
    "    x = np.vstack((x, np.ones((1,n))))\n",
    "    x.shape\n",
    "\n",
    "    delta2=y-T[:,0:n] # Very simple error function of error = model - true = delta2(y)\n",
    "    Q2=np.vstack((h, np.ones((1,n))))@delta2.T  # dE/d W^2 = h * delta_2 \n",
    "    W_hat=W[1]                                  # Weight from input layer W^1\n",
    "    W_hat=W_hat[:-1,:]                          # Remove bias weight from W^1\n",
    "    a_m=np.where(h > 0, 1, 0)                   # Defin the derivativ of ReLU a'=ReLu'\n",
    "    delta1=a_m*(W_hat@delta2)                   # delta_1=a'*(W^1*delta_2)\n",
    "    Q1=x@delta1.T                               # dE/dW^1 = x * delta_1\n",
    "    \n",
    "    #Gradient Decent \n",
    "    W[0]=W[0]-lr*Q1\n",
    "    W[1]=W[1]-lr*Q2\n",
    "    print(f'loop {i}')\n",
    "    return W\n",
    "\n",
    "def train(X, T, dims, epochs, lr, batchsize=1):\n",
    "\n",
    "    # Train the 2-layer network using mini-batch gradient descent.\n",
    "    \n",
    "    # INPUT: X : Training input data, T : Target, dims : (x, z, y) layer size, epochs : Number of epochs\n",
    "    #        lr : Learning rate, batchsize :  Size of mini-batch\n",
    "            \n",
    "    # OUTPUT: W : Trained weights,  losses :Loss at each epoch\n",
    " \n",
    "    \n",
    "    rg = np.random.default_rng()\n",
    "    W = init(dims)\n",
    "    losses = []\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        order = rg.permutation(m)\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for k in range(0, m, batchsize):\n",
    "            batch = order[k:k + batchsize]\n",
    "            X_batch = X[:, batch]\n",
    "            T_batch = T[:, batch]\n",
    "            W, loss = backward(X_batch, T_batch, W, n=batchsize, lr=lr)\n",
    "            epoch_loss += loss\n",
    "            \n",
    "        losses.append(epoch_loss)\n",
    "        print(f\"Epoch {e+1}, loss {epoch_loss:.4f}\")\n",
    "    \n",
    "    return W, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b441220a",
   "metadata": {},
   "source": [
    "# FFNN: Multilayer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40474874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "rg = np.random.default_rng() # random munber generator \n",
    "\n",
    "def init(dims):\n",
    "    \"\"\"\n",
    "    Initialize weights for a multi-layer feedforward neural network.\n",
    "    \n",
    "    INPUT:\n",
    "        dims : Layer dimensions [input, hidden1, hidden2, ..., output]\n",
    "    \n",
    "    OUTPUT:\n",
    "        W : List of weight matrices for each layer.\n",
    "            Each W[l] has shape (dims[l]+1, dims[l+1]) and includes bias weights.\n",
    "    \"\"\"\n",
    "    \n",
    "    W = []\n",
    "    for l in range(len(dims) - 1):\n",
    "        \n",
    "        # initialization for ReLU layers: variance = 2 / fan_in, makes sure variance is stable for relu \n",
    "        fan_in = dims[l] + 1\n",
    "        scale = np.sqrt(2 / fan_in)\n",
    "        W.append(scale * rg.standard_normal(size=(fan_in, dims[l+1])))\n",
    "        \n",
    "    return W\n",
    "\n",
    "\n",
    "def forward(X, W):\n",
    "    \"\"\"\n",
    "    Perform the forward pass through all layers.\n",
    "    \n",
    "    INPUT:\n",
    "        X : Input data (shape: features × samples)\n",
    "        W : Weight matrices for each layer\n",
    "    \n",
    "    OUTPUT:\n",
    "        y : Output of forward with softmax aplied\n",
    "        h : List containing activations (hidden layers and final output pre-softmax)\n",
    "    \"\"\"\n",
    "    \n",
    "    h = []  # store activations of each layer\n",
    "    a = X   # input layer\n",
    "    \n",
    "    # Forward through hidden layers\n",
    "    for l in range(len(W) - 1):\n",
    "        # Add bias term\n",
    "        a = np.vstack((a, np.ones((1, a.shape[1]))))\n",
    "        \n",
    "        # Linear transform\n",
    "        z = W[l].T @ a\n",
    "        \n",
    "        # ReLU activation\n",
    "        a = np.maximum(0, z)\n",
    "        h.append(a)\n",
    "    \n",
    "    # Output layer (no ReLU, only linear before softmax)\n",
    "    a = np.vstack((a, np.ones((1, a.shape[1]))))\n",
    "    y_hat = W[-1].T @ a\n",
    "    h.append(y_hat)\n",
    "    \n",
    "    # Last element in h is pre-softmax output\n",
    "    y_hat = h[-1]\n",
    "    \n",
    "    # Numerically stable softmax\n",
    "    exp_y = np.exp(y_hat - np.max(y_hat, axis=0))\n",
    "    y = exp_y / exp_y.sum(axis=0)\n",
    "    \n",
    "    return y, h\n",
    "\n",
    "\n",
    "#################### Connies code ########################\n",
    "def backward(X, T, W, lr):\n",
    "    \"\"\"\n",
    "    Perform one backward pass and update weights.\n",
    "    \n",
    "    INPUT:\n",
    "        X : Input data (features × samples)\n",
    "        T : Target labels (one-hot encoded)\n",
    "        W : Current weight matrices\n",
    "        lr : Learning rate\n",
    "    \n",
    "    OUTPUT:\n",
    "        W : Updated weight matrices\n",
    "        loss : Total loss for this batch\n",
    "    \"\"\"\n",
    "    \n",
    "    n = X.shape[1]\n",
    "    y, h = forward(X, W)\n",
    "\n",
    "    # --- Loss ---\n",
    "    loss = -np.sum(T * np.log(y + 1e-15)) # cross-entropy loss for multi-class classification\n",
    "    \n",
    "    # --- Backpropagation --- (Like in example above just more layers)\n",
    "    delta = y - T  # output layer error (simple example)\n",
    "    \n",
    "    # --- First layer update ---\n",
    "    x_bias = np.vstack((X, np.ones((1, n))))\n",
    "    Q0 = x_bias @ delta.T\n",
    "    W[0] -= (lr / n) * Q0\n",
    "    \n",
    "    # --- Update all other layers\n",
    "    \n",
    "    for l in range(len(W) - 1, 0, -1):\n",
    "        # Get hidden activation for this layer\n",
    "        h_l = h[l-1] if l-1 >= 0 else X\n",
    "        \n",
    "        # Add bias term\n",
    "        h_l = np.vstack((h_l, np.ones((1, h_l.shape[1]))))\n",
    "        \n",
    "        # Compute gradient for this layer\n",
    "        Q = h_l @ delta.T\n",
    "        \n",
    "        # Update weights\n",
    "        W[l] -= (lr / n) * Q\n",
    "        \n",
    "        # Backpropagate error to previous layer\n",
    "        W_hat = W[l][:-1, :]  # remove bias weights\n",
    "        \n",
    "        if l > 0: # compute delta for next layer\n",
    "            a_prime = (h[l-1] > 0).astype(float)  # ReLU derivative\n",
    "            delta = a_prime * (W_hat @ delta)\n",
    "    \n",
    "    return W, loss\n",
    "\n",
    "\n",
    "def train(X, T, W, epochs, lr, batchsize=1):\n",
    "    \"\"\"\n",
    "    Train the multi-layer neural network using gradient descent.\n",
    "    \n",
    "    INPUT:\n",
    "        X : Input data (features × samples)\n",
    "        T : Target one-hot labels (classes × samples)\n",
    "        W : Initialized weight matrices\n",
    "        epochs :  Number of training epochs\n",
    "        lr : Learning rate\n",
    "        batchsize : Size of each training batch\n",
    "    \n",
    "    OUTPUT:\n",
    "        W : Trained weight matrices\n",
    "        losses : Total loss for each epoch\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    losses = []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        order = rg.permutation(m) # mini-batch is drawn in a random order\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for k in range(0, m, batchsize):\n",
    "            batch = order[k:k+batchsize]\n",
    "            X_batch = X[:, batch]\n",
    "            T_batch = T[:, batch]\n",
    "            \n",
    "            W, loss = backward(X_batch, T_batch, W, lr)\n",
    "            epoch_loss += loss\n",
    "        \n",
    "        losses.append(epoch_loss)\n",
    "        print(f\"Epoch {e+1}, loss {epoch_loss:.4f}\")\n",
    "    \n",
    "    return W, losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23528dcc",
   "metadata": {},
   "source": [
    "# Working w. MNIST minimal change \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d4eb2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 34985.6308\n",
      "Epoch 2/100, Loss: 17472.9261\n",
      "Epoch 3/100, Loss: 14742.8614\n",
      "Epoch 4/100, Loss: 13286.8188\n",
      "Epoch 5/100, Loss: 12259.7355\n",
      "Epoch 6/100, Loss: 11503.5292\n",
      "Epoch 7/100, Loss: 10892.2145\n",
      "Epoch 8/100, Loss: 10359.0255\n",
      "Epoch 9/100, Loss: 9950.5253\n",
      "Epoch 10/100, Loss: 9549.6742\n",
      "Epoch 11/100, Loss: 9191.8536\n",
      "Epoch 12/100, Loss: 8875.2368\n",
      "Epoch 13/100, Loss: 8574.0977\n",
      "Epoch 14/100, Loss: 8297.6192\n",
      "Epoch 15/100, Loss: 8061.5633\n",
      "Epoch 16/100, Loss: 7830.6628\n",
      "Epoch 17/100, Loss: 7627.5116\n",
      "Epoch 18/100, Loss: 7395.5286\n",
      "Epoch 19/100, Loss: 7216.6508\n",
      "Epoch 20/100, Loss: 7040.0610\n",
      "Epoch 21/100, Loss: 6860.6712\n",
      "Epoch 22/100, Loss: 6703.2622\n",
      "Epoch 23/100, Loss: 6557.9555\n",
      "Epoch 24/100, Loss: 6408.4790\n",
      "Epoch 25/100, Loss: 6276.0042\n",
      "Epoch 26/100, Loss: 6125.4974\n",
      "Epoch 27/100, Loss: 6007.6329\n",
      "Epoch 28/100, Loss: 5900.5864\n",
      "Epoch 29/100, Loss: 5778.9336\n",
      "Epoch 30/100, Loss: 5678.3324\n",
      "Epoch 31/100, Loss: 5571.5184\n",
      "Epoch 32/100, Loss: 5485.3398\n",
      "Epoch 33/100, Loss: 5394.9466\n",
      "Epoch 34/100, Loss: 5281.5600\n",
      "Epoch 35/100, Loss: 5216.4390\n",
      "Epoch 36/100, Loss: 5130.8129\n",
      "Epoch 37/100, Loss: 5025.3335\n",
      "Epoch 38/100, Loss: 4959.4759\n",
      "Epoch 39/100, Loss: 4895.8251\n",
      "Epoch 40/100, Loss: 4820.1219\n",
      "Epoch 41/100, Loss: 4741.7989\n",
      "Epoch 42/100, Loss: 4676.8977\n",
      "Epoch 43/100, Loss: 4599.0301\n",
      "Epoch 44/100, Loss: 4541.4413\n",
      "Epoch 45/100, Loss: 4477.7065\n",
      "Epoch 46/100, Loss: 4403.7831\n",
      "Epoch 47/100, Loss: 4354.5636\n",
      "Epoch 48/100, Loss: 4296.9279\n",
      "Epoch 49/100, Loss: 4243.1608\n",
      "Epoch 50/100, Loss: 4192.9885\n",
      "Epoch 51/100, Loss: 4125.8278\n",
      "Epoch 52/100, Loss: 4083.8880\n",
      "Epoch 53/100, Loss: 4025.7941\n",
      "Epoch 54/100, Loss: 3973.7680\n",
      "Epoch 55/100, Loss: 3925.0431\n",
      "Epoch 56/100, Loss: 3888.9216\n",
      "Epoch 57/100, Loss: 3839.8647\n",
      "Epoch 58/100, Loss: 3792.8276\n",
      "Epoch 59/100, Loss: 3739.9114\n",
      "Epoch 60/100, Loss: 3695.3091\n",
      "Epoch 61/100, Loss: 3656.1952\n",
      "Epoch 62/100, Loss: 3607.0946\n",
      "Epoch 63/100, Loss: 3558.7789\n",
      "Epoch 64/100, Loss: 3519.0180\n",
      "Epoch 65/100, Loss: 3480.0615\n",
      "Epoch 66/100, Loss: 3437.3727\n",
      "Epoch 67/100, Loss: 3411.5756\n",
      "Epoch 68/100, Loss: 3372.2320\n",
      "Epoch 69/100, Loss: 3326.4298\n",
      "Epoch 70/100, Loss: 3290.8474\n",
      "Epoch 71/100, Loss: 3267.8341\n",
      "Epoch 72/100, Loss: 3212.4729\n",
      "Epoch 73/100, Loss: 3195.6905\n",
      "Epoch 74/100, Loss: 3154.3797\n",
      "Epoch 75/100, Loss: 3115.2110\n",
      "Epoch 76/100, Loss: 3081.7482\n",
      "Epoch 77/100, Loss: 3052.3699\n",
      "Epoch 78/100, Loss: 3011.2348\n",
      "Epoch 79/100, Loss: 2980.7261\n",
      "Epoch 80/100, Loss: 2947.0307\n",
      "Epoch 81/100, Loss: 2927.8782\n",
      "Epoch 82/100, Loss: 2896.1083\n",
      "Epoch 83/100, Loss: 2852.5466\n",
      "Epoch 84/100, Loss: 2841.2408\n",
      "Epoch 85/100, Loss: 2803.5492\n",
      "Epoch 86/100, Loss: 2780.9078\n",
      "Epoch 87/100, Loss: 2733.9350\n",
      "Epoch 88/100, Loss: 2716.7149\n",
      "Epoch 89/100, Loss: 2694.9421\n",
      "Epoch 90/100, Loss: 2672.3413\n",
      "Epoch 91/100, Loss: 2653.2672\n",
      "Epoch 92/100, Loss: 2610.3633\n",
      "Epoch 93/100, Loss: 2579.5001\n",
      "Epoch 94/100, Loss: 2558.7759\n",
      "Epoch 95/100, Loss: 2530.8881\n",
      "Epoch 96/100, Loss: 2504.0204\n",
      "Epoch 97/100, Loss: 2480.4620\n",
      "Epoch 98/100, Loss: 2443.7571\n",
      "Epoch 99/100, Loss: 2440.9313\n",
      "Epoch 100/100, Loss: 2402.2414\n",
      "Test Accuracy: 96.85%\n"
     ]
    }
   ],
   "source": [
    "### 1. Import Required Libraries\n",
    "\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def softmax(y_hat):\n",
    "    y_hat = y_hat - np.max(y_hat, axis=0, keepdims=True)  # prevent overflow\n",
    "    exp_scores = np.exp(y_hat)\n",
    "    return exp_scores / np.sum(exp_scores, axis=0, keepdims=True)\n",
    "\n",
    "\n",
    "### 2. Load MNIST Data\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape and normalize inputs \n",
    "X_train = X_train.reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.reshape(-1, 28*28) / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "T_train = to_categorical(y_train, num_classes=10)\n",
    "T_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "\n",
    "\n",
    "### 3. Initialize Network Parameters\n",
    "\n",
    "def init(dims):\n",
    "    W = []\n",
    "    for i in range(len(dims) - 1):\n",
    "        W.append(np.random.randn(dims[i] + 1, dims[i + 1]) * np.sqrt(2 / (dims[i])))\n",
    "    return W\n",
    "\n",
    "dims = [784, 32, 32, 10]  # Input layer (784), hidden layer (128), output layer (10)\n",
    "W = init(dims)\n",
    "\n",
    "\n",
    "### 4. Define Forward Pass\n",
    "\n",
    "def forward(X, W):\n",
    "    h = []\n",
    "    a = X\n",
    "    for l in range(len(W) - 1):\n",
    "        a = np.vstack([a, np.ones(a.shape[1])])  # Add bias term\n",
    "        z = W[l].T @ a\n",
    "        a = np.maximum(0, z)  # ReLU activation\n",
    "        h.append(a)\n",
    "    a = np.vstack([a, np.ones(a.shape[1])])  # Add bias term\n",
    "    y_hat = W[-1].T @ a\n",
    "    y = softmax(y_hat)  # new stable version\n",
    "  # Softmax\n",
    "    return y, h\n",
    "\n",
    "\n",
    "### 5. Define Backward Pass\n",
    "\n",
    "def backward(X, T, W, h, eta):\n",
    "    m = X.shape[1]\n",
    "    y, _ = forward(X, W)\n",
    "    delta = y - T\n",
    "    for l in range(len(W) - 1, 0, -1):\n",
    "        a_prev = np.vstack([h[l-1], np.ones(h[l-1].shape[1])])  # Add bias term\n",
    "        Q = a_prev @ delta.T\n",
    "        W[l] -= (eta / m) * Q\n",
    "        delta = W[l][:-1, :] @ delta\n",
    "        delta *= h[l-1] > 0  # ReLU derivative\n",
    "    a_prev = np.vstack([X, np.ones(X.shape[1])])  # Add bias term\n",
    "    Q = a_prev @ delta.T\n",
    "    W[0] -= eta * Q\n",
    "    epsilon = 1e-12\n",
    "    loss = -np.sum(np.log(np.sum(y * T, axis=0) + epsilon))\n",
    "    return W, loss\n",
    "\n",
    "\n",
    "### 6. Training Loop\n",
    "\n",
    "def train(X, T, W, epochs, eta, batchsize=32):\n",
    "    m = X.shape[1]\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        order = np.random.permutation(m)\n",
    "        epoch_loss = 0\n",
    "        for i in range(0, m, batchsize):\n",
    "            batch = order[i:i+batchsize]\n",
    "            X_batch = X[:, batch]\n",
    "            T_batch = T[:, batch]\n",
    "            _, h = forward(X_batch, W)\n",
    "            W, loss = backward(X_batch, T_batch, W, h, eta)\n",
    "            epoch_loss += loss\n",
    "        losses.append(epoch_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "    return W, losses\n",
    "\n",
    "\n",
    "### 7. Train the Model\n",
    "\n",
    "epochs = 100\n",
    "eta = 0.001\n",
    "W, losses = train(X_train.T, T_train.T, W, epochs, eta)\n",
    "\n",
    "### 8. Evaluate the Model\n",
    "\n",
    "def predict(X, W):\n",
    "    y, _ = forward(X, W)\n",
    "    return np.argmax(y, axis=0)\n",
    "\n",
    "y_pred = predict(X_test.T, W)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb1963",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a5dc563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training accuracy: 99.45%\n",
      "Training accuracy: 99.45%\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import numpy as np\n",
    "from Adam import train_ffnn, predict, accuracy  # uses your module\n",
    "\n",
    "# 2. Load your data (example using keras; use your own loader if you already have one)\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), _ = mnist.load_data()\n",
    "X_train = x_train.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
    "T_train = to_categorical(y_train, num_classes=10)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)  \n",
    "print(\"T_train shape:\", T_train.shape)  \n",
    "\n",
    "# 3. Choose optimizer via flag\n",
    "USE_ADAM = True   # False -> plain gradient descent\n",
    "                  # True  -> uses Adam\n",
    "\n",
    "# 4. Define architecture\n",
    "dims = [X_train.shape[1], 32, 16, T_train.shape[1]]  # [784, 32, 16, 10]\n",
    "\n",
    "# 5. Train\n",
    "W, losses = train_ffnn(\n",
    "    X_train,\n",
    "    T_train,\n",
    "    dims,\n",
    "    epochs=100,\n",
    "    lr=1e-3,\n",
    "    batch_size=32,\n",
    "    use_adam=USE_ADAM,\n",
    "    plot=True,\n",
    ")\n",
    "\n",
    "# 6. (optional) reuse W, predict, accuracy here on train/val/test sets\n",
    "# Training accuracy\n",
    "X_col = X_train.T          # (D, N)\n",
    "T_col = T_train.T          # (C, N)\n",
    "train_acc = accuracy(X_col, T_col, W) * 100\n",
    "print(f\"Training accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "\n",
    "# if we have a sperate teste set:\n",
    "# Suppose X_test, T_test (one-hot) are defined\n",
    "\n",
    "# test_acc = accuracy(X_test.T, T_test.T, W) * 100\n",
    "# print(f\"Test accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "\n",
    "# And to get predictions for some samples:\n",
    "\n",
    "# y_pred = predict(X_test.T, W)   # predicted digit for each test image\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
